# sber_scrapy
Тестовое задание для Сбер реализованное на библиотеке Scrapy

### Паук собирает следующую информацию по каждой новостроке:

- Адрес
- Статус
- Количество квартир
- Застройщик
### Если статус здания - "строится", то так же поля:
- Распроданность квартир
- Средняя цена за 1м2
- Кадастровый номер земельного участка

## Описание
После выполнения парсера в файле 'buildings.csv' будут все новостройки на текущий момент.

## Логирование
Сообщения об ошибке логируются в файл 'logs.log'.

## Требования
Python v3.9 + для запуска установите зависимости и виртуальное окружение.
```
$ python -m venv 'название окружения'
$ pip install -r requirements.txt
```
## Запуск
Находясь в директории с файлом выполнить команду:
```
$ scrapy crawl NewBuildings
```

## Дополнительная информация
В случае недоступности страниц, парсер настроен на 5 повторных попыток подключения. Так же включено автоматическое распознование загруженности сервера, для увеличения промежутка времени между запросами.
